{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b5.tar.gz\r\n",
    "!tar -xf noisy_student_efficientnet-b5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Check versions of libraries\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"tensorflow: {tf.__version__}\")\n",
    "\n",
    "print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "TRAINING_SET_DIR = os.path.join(CURRENT_DIR, \"images\", \"training_set\")\n",
    "VALIDATION_SET_DIR = os.path.join(CURRENT_DIR, \"images\", \"validation_set\")\n",
    "NUMBER_OF_TRAINING_IMAGES = 0\n",
    "NUMBER_OF_VALIDATION_IMAGES = 0\n",
    "\n",
    "# Must be the same input size as the base model\n",
    "# Currently using: EfficientNetB5 - (456, 456)\n",
    "IMAGE_WIDTH = 456\n",
    "IMAGE_HEIGHT = 456\n",
    "\n",
    "EPOCHS = 8  # 15 epochs resulted in overtrained model\n",
    "BATCH_SIZE = 24\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator_train = keras.preprocessing.image.ImageDataGenerator(\n",
    "    # rescale=1./255,\n",
    "    brightness_range=[0.4, 1.4],\n",
    "    channel_shift_range=30,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=5,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "data_generator_train = image_generator_train.flow_from_directory(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    directory=TRAINING_SET_DIR,\n",
    "    shuffle=True,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "image_generator_validation = keras.preprocessing.image.ImageDataGenerator(\n",
    "    # rescale=1./255\n",
    ")\n",
    "\n",
    "data_generator_validation = image_generator_validation.flow_from_directory(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    directory=VALIDATION_SET_DIR,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "NUMBER_OF_TRAINING_IMAGES = data_generator_train.samples\n",
    "NUMBER_OF_VALIDATION_IMAGES = data_generator_validation.samples\n",
    "\n",
    "sample_images_train, _ = next(data_generator_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_view(images, rows, columns):\n",
    "    \"\"\"Displays the first NxM images in a NxM subplot\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(rows, columns, figsize=(8, 8))\n",
    "    image_index = 0\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            ax[i, j].imshow(images[image_index].astype(\"uint8\"))\n",
    "            # ax[i, j].imshow(images[image_index])\n",
    "            ax[i, j].axis(\"off\")\n",
    "            image_index += 1\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_view(sample_images_train, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.EfficientNetB5(\r\n",
    "    weights=\"noisy_student_efficientnet-b5.h5\", include_top=False, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)\r\n",
    ")\r\n",
    "\r\n",
    "inputs = keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3))\r\n",
    "x = tf.cast(inputs, dtype=tf.uint8)\r\n",
    "x = base_model(x, training=False)\r\n",
    "\r\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\r\n",
    "# x = keras.layers.Dropout(0.2)(x)\r\n",
    "\r\n",
    "outputs = keras.layers.Dense(130, activation=\"softmax\")(x)\r\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\r\n",
    "\r\n",
    "for layer in base_model.layers:\r\n",
    "    layer.trainable = False\r\n",
    "\r\n",
    "model.compile(\r\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\r\n",
    "    loss=\"categorical_crossentropy\",\r\n",
    "    metrics=[\"accuracy\"]\r\n",
    ")\r\n",
    "\r\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    data_generator_train,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=NUMBER_OF_TRAINING_IMAGES // BATCH_SIZE,\n",
    "    validation_data=data_generator_validation,\n",
    "    validation_steps=NUMBER_OF_VALIDATION_IMAGES // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"new_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history[\"accuracy\"]\n",
    "validation_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "\n",
    "\"\"\"Plot accuracy of model by epochs\"\"\"\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), accuracy, label=\"Training Accuracy\")\n",
    "plt.plot(range(EPOCHS), validation_accuracy, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "\"\"\"Plot loss of model by epochs\"\"\"\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label=\"Training Loss\")\n",
    "plt.plot(range(EPOCHS), validation_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4452f8e62317807c89ffae16391ca0a60fef614c6aa293885399037a1f9691ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}