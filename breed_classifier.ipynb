{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext pycodestyle_magic\n",
    "# %flake8_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.5 (default, May 27 2021, 13:30:53) \n",
      "[GCC 9.3.0]\n",
      "numpy: 1.18.5\n",
      "matplotlib: 3.3.3\n",
      "OpenCV: 4.5.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Check versions of libraries\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"matplotlib: {mpl.__version__}\")\n",
    "print(f\"OpenCV: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "TRAINING_SET_DIR = os.path.join(CURRENT_DIR, \"images\", \"training_set\")\n",
    "VALIDATION_SET_DIR = os.path.join(CURRENT_DIR, \"images\", \"validation_set\")\n",
    "\n",
    "IMAGE_WIDTH = 300\n",
    "IMAGE_HEIGHT = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotations(xml_file: str):\n",
    "    \"\"\"https://stackoverflow.com/questions/53317592/reading-pascal-voc-annotations-in-python\n",
    "    Parses the annotation file and returns the bounding boxes and breed names\"\"\"\n",
    "\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    all_bounding_boxes = []\n",
    "    all_breed_names = []\n",
    "\n",
    "    for boxes in root.iter(\"object\"):\n",
    "        breed_name = root.find(\"object\").find(\"name\").text\n",
    "        all_breed_names.append(breed_name)\n",
    "\n",
    "        xmin, xmax, ymin, ymax = None, None, None, None\n",
    "\n",
    "        # Finds the bounding box coordinates of the dog within the image\n",
    "        xmin = int(boxes.find(\"bodybndbox/xmin\").text)\n",
    "        xmax = int(boxes.find(\"bodybndbox/xmax\").text)\n",
    "        ymin = int(boxes.find(\"bodybndbox/ymin\").text)\n",
    "        ymax = int(boxes.find(\"bodybndbox/ymax\").text)\n",
    "\n",
    "        bounding_box = (xmin, ymin, xmax, ymax)\n",
    "        all_bounding_boxes.append(bounding_box)\n",
    "\n",
    "    return all_bounding_boxes, all_breed_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_set_dir, image_width, image_height):\n",
    "    \"\"\"Loads image data and breed names from directory\"\"\"\n",
    "\n",
    "    # Lists for image data and breed names\n",
    "    image_data = []\n",
    "    all_bounding_boxes = []\n",
    "    all_breed_names = []\n",
    "\n",
    "    # Iterates the files as (with the help of sorted()):\n",
    "    # breedId1_dogId1\n",
    "    # breedId1_dogId1.jpg\n",
    "    # breedId1_dogId2\n",
    "    # breedId1_dogId2.jpg\n",
    "    # ...\n",
    "    # breedId120_dogIdX.jpg\n",
    "    for breed_folder in os.listdir(image_set_dir):\n",
    "        for file in sorted(os.listdir(os.path.join(image_set_dir, breed_folder))):\n",
    "            file_path = os.path.join(image_set_dir, breed_folder, file)\n",
    "\n",
    "            # Checks images to resize and crop according to its bounding box\n",
    "            if file_path.endswith(\".jpg\") or file_path.endswith(\".jpeg\"):\n",
    "                image = cv2.imread(file_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Did not resize nor crop images\n",
    "                # Only add the raw image to the list\n",
    "                image_data.append(image)\n",
    "\n",
    "            # Checks annotation files for the dog's breed and its bounding boxes\n",
    "            elif file_path.endswith(\".xml\"):\n",
    "                bounding_boxes, breed_names = parse_annotations(file_path)\n",
    "\n",
    "                # May have multiple dogs and bounding boxes for 1 image\n",
    "                all_bounding_boxes.append(bounding_boxes)\n",
    "                all_breed_names.append(breed_names)\n",
    "\n",
    "    return image_data, all_bounding_boxes, all_breed_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_train, bounding_boxes_train, breed_names_train\\\n",
    "    = load_data(TRAINING_SET_DIR, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "image_data_validation, bounding_boxes_validation, breed_names_validation\\\n",
    "    = load_data(VALIDATION_SET_DIR, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "print(f\"Training images: {len(image_data_train)}\")\n",
    "print(f\"Valdiation images: {len(image_data_validation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, bounding_boxes, breed_names, image_width, image_height):\n",
    "    \"\"\"Augments one image and its bounding boxes\n",
    "\n",
    "\n",
    "    Following these:\n",
    "    https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/\n",
    "    \"\"\"\n",
    "\n",
    "    # Augment the image and its bounding boxes\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Affine(translate_percent=(0, 0.2), rotate=(-30, 30)),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.Blur(),\n",
    "        A.Resize(width=image_width, height=image_height),\n",
    "    ], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]))\n",
    "\n",
    "    # Note: bboxes expect a list of multiple bounding boxes\n",
    "    # [[xmin, ymin, xmax, ymax], [xmin, ymin, xmax, ymax], ...]\n",
    "    # class_labels expect a list of strings\n",
    "    # [\"class1\", \"class2\", ...]\n",
    "    transformed = transform(image=image, bboxes=bounding_boxes, class_labels=breed_names)\n",
    "\n",
    "    transformed_image = transformed[\"image\"]\n",
    "    transformed_bounding_boxes = transformed[\"bboxes\"]\n",
    "    transformed_class_labels = transformed[\"class_labels\"]\n",
    "\n",
    "    return transformed_image, transformed_bounding_boxes, transformed_class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Testing data augmentation with the first training image\"\"\"\n",
    "test_image, test_bounding_box, test_labels = augment_image(image_data_train[0],\n",
    "                                                            bounding_boxes_train[0],\n",
    "                                                            breed_names_train[0],\n",
    "                                                            IMAGE_WIDTH,\n",
    "                                                            IMAGE_HEIGHT)\n",
    "\n",
    "plt.imshow(test_image)\n",
    "plt.title(f\"Breed: {test_labels}\")\n",
    "\n",
    "# Create a visual bounding box\n",
    "bounding_box = mpl.patches.Rectangle((test_bounding_box[0][0], test_bounding_box[0][1]),\n",
    "                                            test_bounding_box[0][2] - test_bounding_box[0][0],\n",
    "                                            test_bounding_box[0][3] - test_bounding_box[0][1],\n",
    "                                            linewidth=1,\n",
    "                                            edgecolor='r',\n",
    "                                            facecolor='none')\n",
    "plt.gca().add_patch(bounding_box)\n",
    "\n",
    "plt.show()\n",
    "print(test_bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_view(images, labels):\n",
    "    \"\"\"Displays a 3x3 subplot of randomly selected images\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # Selects a random image and displays it\n",
    "            index = random.randint(0, len(images) - 1)\n",
    "            ax[i, j].imshow(images[index])\n",
    "\n",
    "            # Displays the breed's name as the title\n",
    "            ax[i, j].set_title(f\"Breed: {labels[index]}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_view(image_data_train, breed_names_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
