{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b1.tar.gz\r\n",
    "!tar -xf noisy_student_efficientnet-b5.tar.gz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "import random\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "# Check versions of libraries\r\n",
    "print(f\"Python: {sys.version}\")\r\n",
    "print(f\"numpy: {np.__version__}\")\r\n",
    "print(f\"tensorflow: {tf.__version__}\")\r\n",
    "\r\n",
    "print(tf.config.list_physical_devices(\"GPU\"))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CURRENT_DIR = os.getcwd()\r\n",
    "TRAINING_SET_DIR = os.path.join(CURRENT_DIR, \"images\", \"training_set\")\r\n",
    "VALIDATION_SET_DIR = os.path.join(CURRENT_DIR, \"images\", \"validation_set\")\r\n",
    "NUMBER_OF_TRAINING_IMAGES = 0\r\n",
    "NUMBER_OF_VALIDATION_IMAGES = 0\r\n",
    "\r\n",
    "# Must be the same input size as the base model\r\n",
    "# Currently using: EfficientNetB5 - (456, 456)\r\n",
    "IMAGE_WIDTH = 240\r\n",
    "IMAGE_HEIGHT = 240\r\n",
    "\r\n",
    "EPOCHS = 10  # 15 epochs resulted in overtrained model\r\n",
    "BATCH_SIZE = 24\r\n",
    "LEARNING_RATE = 0.001"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_generator_train = keras.preprocessing.image.ImageDataGenerator(\r\n",
    "    # rescale=1./255,\r\n",
    "    brightness_range=[0.4, 1.4],\r\n",
    "    channel_shift_range=30,\r\n",
    "    rotation_range=30,\r\n",
    "    width_shift_range=0.1,\r\n",
    "    height_shift_range=0.1,\r\n",
    "    shear_range=5,\r\n",
    "    zoom_range=0.1,\r\n",
    "    horizontal_flip=True,\r\n",
    ")\r\n",
    "\r\n",
    "data_generator_train = image_generator_train.flow_from_directory(\r\n",
    "    batch_size=BATCH_SIZE,\r\n",
    "    directory=TRAINING_SET_DIR,\r\n",
    "    shuffle=True,\r\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\r\n",
    "    class_mode=\"categorical\"\r\n",
    ")\r\n",
    "\r\n",
    "image_generator_validation = keras.preprocessing.image.ImageDataGenerator(\r\n",
    "    # rescale=1./255\r\n",
    ")\r\n",
    "\r\n",
    "data_generator_validation = image_generator_validation.flow_from_directory(\r\n",
    "    batch_size=BATCH_SIZE,\r\n",
    "    directory=VALIDATION_SET_DIR,\r\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\r\n",
    "    class_mode=\"categorical\"\r\n",
    ")\r\n",
    "\r\n",
    "NUMBER_OF_TRAINING_IMAGES = data_generator_train.samples\r\n",
    "NUMBER_OF_VALIDATION_IMAGES = data_generator_validation.samples\r\n",
    "\r\n",
    "sample_images_train, _ = next(data_generator_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def image_view(images, rows, columns):\r\n",
    "    \"\"\"Displays the first NxM images in a NxM subplot\"\"\"\r\n",
    "\r\n",
    "    fig, ax = plt.subplots(rows, columns, figsize=(8, 8))\r\n",
    "    image_index = 0\r\n",
    "\r\n",
    "    for i in range(rows):\r\n",
    "        for j in range(columns):\r\n",
    "            ax[i, j].imshow(images[image_index].astype(\"uint8\"))\r\n",
    "            # ax[i, j].imshow(images[image_index])\r\n",
    "            ax[i, j].axis(\"off\")\r\n",
    "            image_index += 1\r\n",
    "\r\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_view(sample_images_train, 3, 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_model = keras.applications.EfficientNetB5(\r\n",
    "    weights=\"noisy_student_efficientnet-b1.h5\", include_top=False, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)\r\n",
    ")\r\n",
    "\r\n",
    "inputs = keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3))\r\n",
    "x = tf.cast(inputs, dtype=tf.uint8)\r\n",
    "x = base_model(x, training=False)\r\n",
    "\r\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\r\n",
    "# x = keras.layers.Dropout(0.2)(x)\r\n",
    "\r\n",
    "outputs = keras.layers.Dense(130, activation=\"softmax\")(x)\r\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\r\n",
    "\r\n",
    "for layer in base_model.layers:\r\n",
    "    layer.trainable = False\r\n",
    "\r\n",
    "model.compile(\r\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\r\n",
    "    loss=\"categorical_crossentropy\",\r\n",
    "    metrics=[\"accuracy\"]\r\n",
    ")\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = model.fit(\r\n",
    "    data_generator_train,\r\n",
    "    epochs=EPOCHS,\r\n",
    "    steps_per_epoch=NUMBER_OF_TRAINING_IMAGES // BATCH_SIZE,\r\n",
    "    validation_data=data_generator_validation,\r\n",
    "    validation_steps=NUMBER_OF_VALIDATION_IMAGES // BATCH_SIZE\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save(\"efficientnetb1-noisystudent-10epochs\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy = history.history[\"accuracy\"]\r\n",
    "validation_accuracy = history.history[\"val_accuracy\"]\r\n",
    "\r\n",
    "loss = history.history[\"loss\"]\r\n",
    "validation_loss = history.history[\"val_loss\"]\r\n",
    "\r\n",
    "\"\"\"Plot accuracy of model by epochs\"\"\"\r\n",
    "plt.figure(figsize=(8, 8))\r\n",
    "plt.subplot(1, 2, 1)\r\n",
    "plt.plot(range(EPOCHS), accuracy, label=\"Training Accuracy\")\r\n",
    "plt.plot(range(EPOCHS), validation_accuracy, label=\"Validation Accuracy\")\r\n",
    "plt.legend(loc=\"lower right\")\r\n",
    "plt.title(\"Training and Validation Accuracy\")\r\n",
    "\r\n",
    "\"\"\"Plot loss of model by epochs\"\"\"\r\n",
    "plt.subplot(1, 2, 2)\r\n",
    "plt.plot(range(EPOCHS), loss, label=\"Training Loss\")\r\n",
    "plt.plot(range(EPOCHS), validation_loss, label=\"Validation Loss\")\r\n",
    "plt.legend(loc=\"upper right\")\r\n",
    "plt.title(\"Training and Validation Loss\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4452f8e62317807c89ffae16391ca0a60fef614c6aa293885399037a1f9691ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}